---
title: "TEDS-D Data Exploration and Cleaning"
author: "Valerie Jill Sydnor"
date: "4/26/2019"
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
    fig_caption: yes
    keep_tex: yes
  html_document:
    code_folding: show
    highlight: pygments 
    toc: yes
    toc_depth: 4
    toc_float: yes
    df_print: kable
theme: paper
geometry: margin=1.9cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(randomForest, tree, ISLR, rpart, rattle, pROC, partykit, ggplot2, glmnet, leaps, dplyr, rsample, gbm, SnowballC, ranger, BiocManager, keras, neuralnet, xtable, tidyverse, mapproj, psych, caret, logisticPCA, JOUSBoost)
knitr::opts_chunk$set(options(xtable.comment = FALSE))
knitr::opts_chunk$set(comment = " ")
```

____________________________________Data Cleaning and Variable Selection____________________________________

```{r eval=FALSE, include=FALSE}
# Read in Data:
drugdata <- read.csv("../TEDSD2006.csv", header=T, na.strings="-9")
```

```{r eval=FALSE, include=FALSE}
# Remove 24-Hour Detoxes and Ambulatory Detox:
drugdata.cleaned <- drugdata %>% filter(SERVSETD == "4" | SERVSETD == "5" | SERVSETD == "6" | SERVSETD == "7")
```


```{r,  eval=FALSE, include=FALSE}
# Remove Participants with Prior Treatment:
drugdata.cleaned <- drugdata.cleaned %>% filter(NOPRIOR == 0)
``` 


```{r,  eval=FALSE, include=FALSE}
# Remove Columns of Non-Interest, Low Interpretability or Redundancy:
drugdata.cleaned <- drugdata.cleaned %>% dplyr::select(-FREQ2, -FREQ3, -FRSTUSE2, -FRSTUSE3, -ROUTE2, -ROUTE3, -STFIPS, -SUB2, -SUB3, -CBSA, -PMSA, -DSMCRIT, -CASEID, -DISYR, -REGION, - NOPRIOR, -ARRESTS)
```


```{r,  eval=FALSE, include=FALSE}
# Look at NAs per Column:
sapply(drugdata.cleaned, function(x) sum(is.na(x)))
```


```{r,  eval=FALSE, include=FALSE}
# Remove Columns with too many NAs:
# DETNLF = 75% NAs
# PREG = 67%
# DETCRIM = 70%
# HLTHINS = 45%
# PRIMPAY = 52%
drugdata.cleaned <- drugdata.cleaned %>% dplyr::select(-DETNLF, -PREG, -DETCRIM, -PRIMPAY, -HLTHINS)
```


```{r,  eval=FALSE, include=FALSE}
# Remove Rows with NAs:
drugdata.cleaned <- na.omit(drugdata.cleaned)
sapply(drugdata.cleaned, function(x) sum(is.na(x))) #check
```


```{r,  eval=FALSE, include=FALSE}
# Look at Variable Class:
for(var in c("AGE", "GENDER","RACE","ETHNIC","MARSTAT", "EMPLOY", "EDUC","VET",
             "LIVARAG", "PRIMINC", "DIVISION", "SERVSETD", "METHUSE", 
             "PSOURCE", "SUB1", "ROUTE1", "FREQ1", "FRSTUSE1", "IDU", "ALCDRUG","PSYPROB")){
      drugdata.cleaned[,var] <- as.factor(drugdata.cleaned[,var])
}


drugdata.cleaned[ , grepl('FLG', names(drugdata.cleaned)) ] <- lapply(drugdata.cleaned[ , grepl('FLG' , names(drugdata.cleaned)) ], factor)    
sapply(drugdata.cleaned, function(x) class(x))
```


```{r,  eval=FALSE, include=FALSE}
# RECODE VARIABLE OF INTEREST:
for(num in c(2:8)){
drugdata.cleaned$REASON[drugdata.cleaned$REASON == num] <- 0
}
```

```{r,  eval=FALSE, include=FALSE}
# Look at Within-Variable Variability:
sapply(drugdata.cleaned, function(x) table(x))
```

```{r,  eval=FALSE, include=FALSE}
# Write Out Finalized Dataset:
write.csv(x = drugdata.cleaned, file="./Data/TEDS-D_DrugTreatment_Outcomes_Final.csv", sep=",", row.names = FALSE)
```

____________________________________Read in Cleaned Data____________________________________

```{r, echo=F}
# Read in Cleaned Data
drug.data <- read.csv("./Data/TEDS-D_DrugTreatment_Outcomes_Final.csv", sep=",", header=T)

drug.data <- drug.data %>% rename(TREATCOMPLETE = REASON)

#Change Variable Classes
for(var in c("AGE", "GENDER","RACE","ETHNIC","MARSTAT", "EMPLOY", "EDUC","VET",
             "LIVARAG", "PRIMINC", "TREATCOMPLETE","DIVISION", "SERVSETD", "METHUSE", 
             "PSOURCE", "SUB1", "ROUTE1", "FREQ1", "FRSTUSE1", "IDU", "ALCDRUG","PSYPROB")){
      drug.data[,var] <- as.factor(drug.data[,var])
}

drug.data[ , grepl('FLG', names(drug.data)) ] <- lapply(drug.data[ , grepl('FLG' , names(drug.data)) ], factor)    
```

____________________________________Sample Info____________________________________

```{r sample characteristics, eval=FALSE, include=FALSE}
#Demographics 
table(drug.data$AGE)
table(drug.data$GENDER)
table(drug.data$RACE)
table(drug.data$MARSTAT)
table(drug.data$EDUC)
table(drug.data$EMPLOY)

#Drug Use Information
table(drug.data$SUB1)
table(drug.data$FRSTUSE1)
table(drug.data$ALCDRUG)

#Treatment Information
table(drug.data$SERVSETD)
table(drug.data$DAYWAIT)
table(drug.data$LOS)
```

____________________________________PCA on Admission Drugs____________________________________

```{r PCA Set Up, echo=F}
# Logistic Principal Component Analysis for Dimensionality Reduction of Drug Admissions Data
# Input: Drug Flags --> Flags indicate whether each drug was reported as in use at admission (0=no, 1=yes) for 18 drugs

# Step 1. Get drug flag data for input into logistic PCA
pca.data <- drug.data[, c(24:41)]
for(var in c(1:18)){
      pca.data[,var] <- as.numeric(pca.data[,var]) 
}
pca.data$ALCFLG[pca.data$ALCFLG == 1] <- 0
pca.data$ALCFLG[pca.data$ALCFLG == 2] <- 1
pca.data$COKEFLG[pca.data$COKEFLG == 1] <- 0
pca.data$COKEFLG[pca.data$COKEFLG == 2] <- 1
pca.data$MARFLG[pca.data$MARFLG== 1] <- 0
pca.data$MARFLG[pca.data$MARFLG == 2] <- 1
pca.data$HERFLG[pca.data$HERFLG== 1] <- 0
pca.data$HERFLG[pca.data$HERFLG == 2] <- 1
pca.data$METHFLG[pca.data$METHFLG== 1] <- 0
pca.data$METHFLG[pca.data$METHFLG == 2] <- 1
pca.data$OPSYNFLG[pca.data$OPSYNFLG== 1] <- 0
pca.data$OPSYNFLG[pca.data$OPSYNFLG == 2] <- 1
pca.data$PCPFLG[pca.data$PCPFLG== 1] <- 0
pca.data$PCPFLG[pca.data$PCPFLG == 2] <- 1
pca.data$HALLFLG[pca.data$HALLFLG == 1] <- 0
pca.data$HALLFLG[pca.data$HALLFLG == 2] <- 1
pca.data$MTHAMFLG[pca.data$MTHAMFLG== 1] <- 0
pca.data$MTHAMFLG[pca.data$MTHAMFLG == 2] <- 1
pca.data$AMPHFLG[pca.data$AMPHFLG== 1] <- 0
pca.data$AMPHFLG[pca.data$AMPHFLG == 2] <- 1
pca.data$STIMFLG[pca.data$STIMFLG== 1] <- 0
pca.data$STIMFLG[pca.data$STIMFLG == 2] <- 1
pca.data$BENZFLG[pca.data$BENZFLG== 1] <- 0
pca.data$BENZFLG[pca.data$BENZFLG == 2] <- 1
pca.data$TRNQFLG[pca.data$TRNQFLG== 1] <- 0
pca.data$TRNQFLG[pca.data$TRNQFLG == 2] <- 1
pca.data$BARBFLG[pca.data$BARBFLG== 1] <- 0
pca.data$BARBFLG[pca.data$BARBFLG == 2] <- 1
pca.data$SEDHPFLG[pca.data$SEDHPFLG== 1] <- 0
pca.data$SEDHPFLG[pca.data$SEDHPFLG == 2] <- 1
pca.data$INHFLG[pca.data$INHFLG== 1] <- 0
pca.data$INHFLG[pca.data$INHFLG == 2] <- 1
pca.data$OTCFLG[pca.data$OTCFLG== 1] <- 0
pca.data$OTCFLG[pca.data$OTCFLG == 2] <- 1
pca.data$OTHERFLG[pca.data$OTHERFLG== 1] <- 0
pca.data$OTHERFLG[pca.data$OTHERFLG == 2] <- 1
```

```{r PCA Tune, eval=FALSE, include=FALSE}

# Step 2. Tune Parameter K. Choose K=6!
logpca_model_k1_m5 = logisticPCA(pca.data, k = 1, m = 5)
logpca_model_k1_m5$prop_deviance_expl #27%

logpca_model_k2_m5 = logisticPCA(pca.data, k = 2, m = 5)
logpca_model_k2_m5$prop_deviance_expl #53%

logpca_model_k3_m5 = logisticPCA(pca.data, k = 3, m = 5)
logpca_model_k3_m5$prop_deviance_expl #70%

logpca_model_k4_m5 = logisticPCA(pca.data, k = 4, m = 5)
logpca_model_k4_m5$prop_deviance_expl #79%

logpca_model_k5_m5 = logisticPCA(pca.data, k = 5, m = 5)
logpca_model_k5_m5$prop_deviance_expl #84%

logpca_model_k6_m5 = logisticPCA(pca.data, k = 6, m = 5)
logpca_model_k6_m5$prop_deviance_expl #88%

logpca_model_k7_m5 = logisticPCA(pca.data, k = 7, m = 5)
logpca_model_k7_m5$prop_deviance_expl #90%

#Step 3. Tune Parameter M (if m not specified, best m is solved for at given K)
logpca_final_model = logisticPCA(pca.data, k = 6, m=0)
logpca_final_model$prop_deviance_expl #94%
save(logpca_final_model, file="./logpca_final_model.Rdata") #Save out results of PCA
```

```{r PCA Get PCs, echo=F}
load("./logpca_final_model.Rdata") #Read in results of PCA

# Step 4. Add PC Scores to drug data 
PCs <- data.frame(logpca_final_model$PCs) 
drug.data$PC1 <- PCs$X1
drug.data$PC2 <- PCs$X2
drug.data$PC3 <- PCs$X3
drug.data$PC4 <- PCs$X4
drug.data$PC5 <- PCs$X5
drug.data$PC6 <- PCs$X6
drug.data <- drug.data %>% select(-ends_with("FLG"))
```

__________Extract Training (N=40,000), Testing (N=20,000) and Validation (N=5,009) Datasets_____________

```{r, echo=F}

#Extract training and testing data
set.seed(256)

N <- nrow(drug.data)
index.train <- sample(N, 45000)
drugdata.train <- drug.data[index.train,]
drugdata.test <- drug.data[-index.train,]

N <- nrow(drugdata.test)
index.validation <- sample(N, 5009)
drugdata.validation <- drugdata.test[index.validation,]
drugdata.test <- drugdata.test[-index.validation,]
```

____________________________________Statistics____________________________________

GLM with All Predictors (Val):

```{r GLM Full Model Val, include=FALSE}

# Step 1. Fit a logistic regression with all possible predictors
glm.allpredictors <- glm(TREATCOMPLETE ~ ., family=binomial, data=drugdata.train) 

# Step 2. Get fitted values and classification for testing data
glm.allpredictors.fittedprobabilities <- predict(glm.allpredictors, drugdata.test, type="response")  #Get probabilities
glm.allpredictors.classify <- ifelse(glm.allpredictors.fittedprobabilities > 0.5, "1", "0") #Classify

# Step 3. Evaluate

#MCE
testingerror.glm.allpredictors.MCE <- mean(drugdata.test$TREATCOMPLETE != glm.allpredictors.classify) # MCE= 0.3077 = FINAL TESTING ERROR FOR A LOGISTIC REGRESSION WITH ALL PREDICTORS

#AUC
glm.allpredictors.roc <- roc(drugdata.test$TREATCOMPLETE, glm.allpredictors.fittedprobabilities, plot=F) #AUC= 0.7561
```

Neural Net (Val):

```{r eval=FALSE, include=FALSE, Neural Net Val, echo=F}

# Step 1. Define the Model

model <- keras_model_sequential() %>%
  layer_dense(units = 20, activation = "relu", input_shape = c(30)) %>% 
  layer_dense(units = 10, activation = "relu") %>%
   layer_dense(units = 10, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

# Step 2. Compile the Model

model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

#Step 3. Train the Model
## Determine Epoch number using training and validation data sets

### Format Data
x_train <- as.matrix(drugdata.train[,-15])
y_train <- as.matrix(drugdata.train[,15])
x_validate <- as.matrix(drugdata.validation[,-15])
y_validate <- as.matrix(drugdata.validation[,15])
x_test <- as.matrix(drugdata.test[,-15])
y_test <- as.matrix(drugdata.test[,15])

### Train
neuralnet.tune <- model %>% fit(x_train, 
                                y_train,
                                epochs = 30, 
                                batch_size = 1000, 
                                validation_data = list(x_validate, y_validate)
                                )

```

```{r include=FALSE}
# Step 4. Refit Model with Chosen Parameters

set.seed(1)
# FINAL MODEL
model <- keras_model_sequential() %>%
  layer_dense(units = 20, activation = "relu", input_shape = c(30)) %>% 
  layer_dense(units = 10, activation = "relu") %>%
   layer_dense(units = 10, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

x_train <- as.matrix(drugdata.train[,-15])
y_train <- as.matrix(drugdata.train[,15])
x_test <- as.matrix(drugdata.test[,-15])
y_test <- as.matrix(drugdata.test[,15])

NN.allpredictors <- model %>% fit(x_train, y_train, epochs = 25, batch_size = 1000)

# Step 5. Evaluate 

## AUC 
results <- model %>% evaluate(x_test, y_test)

## MCE
MCE.NN <- 1-results$acc # MCE = 0.332 = FINAL TESTING ERROR FOR NEURAL NET

NN_predict_classes <- predict_classes(object = model,
                                    x = as.matrix(x_test)) %>%
  as.vector()

testingerror.NN.MCE <- mean(y_test != NN_predict_classes) 


#AUC Plot
NN_predictions <- predict(object = model,
                                    x = as.matrix(x_test)) %>%
  as.vector()

NN.roc <- roc(drugdata.test$TREATCOMPLETE, NN_predictions, plot=F) #AUC = 0.7447
```

Boosting Trees ADABOOST (Val):

```{r Boosting Val, eval=FALSE, include=FALSE}

# Step 1. Format Data
x.train <- (drugdata.train[,-(15)]) 
y.train <- as.numeric(drugdata.train[,15]) -1
y.train[y.train == 0] = -1

x.test <- (drugdata.test[,-(15)])
y.test <- as.numeric(drugdata.test[,15]) -1
predictions

# Step 2. Boost
## Tune Parameters
###Tune tree depth (try 3, 5, 6, 7, 8, 10). We choose a tree depth of 6 to lower testing error!
boost.3.30 <- adaboost(data.matrix(x.train), y.train, tree_depth = 3, n_rounds = 30,
                    verbose = FALSE,
                   control = NULL)
yhat_train_ada <- predict(boost.3.30, data.matrix(x.train))
train_err.3.30 <- mean(y.train != yhat_train_ada) #0.2944
yhat_test_ada <- predict(boost.3.30, data.matrix(x.test))
test_err.3.30 <- mean(y.test != yhat_test_ada) #0.301

boost.5.30 <- adaboost(data.matrix(x.train), y.train, tree_depth = 5, n_rounds = 30,
                    verbose = FALSE,
                   control = NULL)
yhat_train_ada <- predict(boost.5.30, data.matrix(x.train))
train_err.5.30 <- mean(y.train != yhat_train_ada) #0.275
yhat_test_ada <- predict(boost.5.30, data.matrix(x.test))
test_err.5.30 <- mean(y.test != yhat_test_ada) #0.2907


boost.6.30 <- adaboost(data.matrix(x.train), y.train, tree_depth = 6, n_rounds = 30,
                    verbose = FALSE,
                   control = NULL)
yhat_train_ada <- predict(boost.6.30, data.matrix(x.train))
train_err.6.30 <- mean(y.train != yhat_train_ada) #0.2578
yhat_test_ada <- predict(boost.6.30, data.matrix(x.test))
test_err.6.30 <- mean(y.test != yhat_test_ada) #0.28425

boost.7.30 <- adaboost(data.matrix(x.train), y.train, tree_depth = 7, n_rounds = 30,
                    verbose = FALSE,
                   control = NULL)
yhat_train_ada <- predict(boost.7.30, data.matrix(x.train))
train_err.7.30 <- mean(y.train != yhat_train_ada) #0.242
yhat_test_ada <- predict(boost.7.30, data.matrix(x.test))
test_err.7.30 <- mean(y.test != yhat_test_ada) #0.2863

boost.8.30 <- adaboost(data.matrix(x.train), y.train, tree_depth = 8, n_rounds = 30,
                    verbose = FALSE,
                   control = NULL)
yhat_train_ada <- predict(boost.8.30, data.matrix(x.train))
train_err.8.30 <- mean(y.train != yhat_train_ada) #0.2165
yhat_test_ada <- predict(boost.8.30, data.matrix(x.test))
test_err.8.30 <- mean(y.test != yhat_test_ada) #0.292

boost.10.30 <- adaboost(data.matrix(x.train), y.train, tree_depth = 10, n_rounds = 30,
                    verbose = FALSE,
                   control = NULL)
yhat_train_ada <- predict(boost.10.30, data.matrix(x.train))
train_err.10.30 <- mean(y.train != yhat_train_ada) #0.1148
yhat_test_ada <- predict(boost.10.30, data.matrix(x.test))
test_err.10.30 <- mean(y.test != yhat_test_ada) #0.2979

#Tune n_rounds

boost.6.50 <- adaboost(data.matrix(x.train), y.train, tree_depth = 6, n_rounds = 50,
                    verbose = FALSE,
                   control = NULL)
yhat_train_ada <- predict(boost.6.50, data.matrix(x.train))
train_err.6.50 <- mean(y.train != yhat_train_ada) #0.247
yhat_test_ada <- predict(boost.6.50, data.matrix(x.test))
test_err.6.50 <- mean(y.test != yhat_test_ada) #0.28422
```

```{r FINAL BOOSTING TREES, echo=F}

#FINAL BOOSTING TREES MODEL
x.train <- (drugdata.train[,-(15)]) 
y.train <- as.numeric(drugdata.train[,15]) -1
y.train[y.train == 0] = -1

x.test <- (drugdata.test[,-(15)])
y.test <- as.numeric(drugdata.test[,15]) -1
y.test[y.test == 0] = -1

#boost.6.100 <- adaboost(data.matrix(x.train), y.train, tree_depth = 6, n_rounds = 500,
  #                  verbose = FALSE,
   #                control = NULL)
#save(boost.6.100, file="./final_boosting_model.Rdata") #Save out final model
load("./final_boosting_model.Rdata")

# Step 3. Evaluate

#yhat_train_ada <- predict(boost.6.100, data.matrix(x.train))
#train_err.6.100 <- mean(y.train != yhat_train_ada) #0.2231 = TRAINING ERROR 0.2231

#MCE
yhat_test_ada <- predict(boost.6.100, data.matrix(x.test))
testingerror.boosting.6.100.MCE <- mean(y.test != yhat_test_ada) # MCE = 0.27945 = FINAL TESTING ERROR FOR BOOSTING TREES

#AUC
boosting.fitted <- predict(boost.6.100, data.matrix(drugdata.test), type="response") 
boosting.fitted[boosting.fitted == -1] = 0
boosting.roc <- roc(drugdata.test$TREATCOMPLETE, boosting.fitted, plot=F) #AUC = 0.72
```

Boosting Trees GBM (Val):

```{r Boosting Val GBM, include=FALSE}

# Step 1. Format Data
x.boost.train <- drugdata.train[,-15]
y.boost.train <- make.names(drugdata.train[,15])
x.boost.test <- drugdata.test[,-15]
y.boost.test <- drugdata.test[,15]

# Step 2: Tune Boosting Parameters
fitControl <- trainControl(method = "cv",
                           number = 5,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary)
gbmGrid <-  expand.grid(interaction.depth = c(2, 4, 6, 8), 
                        n.trees = (1:10)*100, 
                        shrinkage = 0.1,
                        n.minobsinnode = 20)
GBM.boosting.model <- train(x.boost.train,y.boost.train, 
                 method='gbm', 
                  trControl=fitControl,
                  tuneGrid = gbmGrid,
                  metric = "ROC")

print(GBM.boosting.model)
save(GBM.boosting.model, file="./GBM_Boosting_Model.Rdata") #Save out final model
load("./GBM_Boosting_Model.Rdata")

# Step 3. Evaluate
predictions <- predict(object=GBM.boosting.model, x.boost.test, type='prob')
boosting.probabilities <- predictions[,2]
boosting.classify <- ifelse(boosting.probabilities > 0.5, "1", "0")
testingerror.boost.MCE <- mean(drugdata.test$TREATCOMPLETE != boosting.classify) #TESTING ERROR = 0.27055
gbmboost.roc <- roc(drugdata.test$TREATCOMPLETE, boosting.probabilities, plot=F) #AUC = 0.8028
importantpredictors <- summary(GBM.boosting.model)
```

```{r echo=FALSE}
# Boosting 15 MOST IMPORTANT PREDICTORS
importantpredictors.df <- data.frame(importantpredictors)
rownames(importantpredictors.df) <- c()
importantpredictors.df <- importantpredictors.df %>% rename(Variable = var)
importantpredictors.df <- importantpredictors.df %>% rename(Relative_Influence = rel.inf)
importantpredictors.df[1:15,]

# BOOSTING PREDICTOR RELATIVE INFLUENCE GRAPH
plot(varImp(GBM.boosting.model,scale=F, xlab="Variable Importance"))
```

Compare Val Models (GLM, NN, Boosting) with AUC CURVES:

```{r PLOT ROCs,fig.height=5, fig.width=9, echo=F}
par(mfrow=c(1,1))
plot(1-NN.roc$specificities, NN.roc$sensitivities, col="steelblue3", pch=16, cex=0.4, xlab= "False Positives", ylab="Sensitivities", font.lab=2, main="Model Comparisons: ROC Curves", font.main=2,
text(.75, .2, paste("\nModel 1: Boosting AUC=", round(pROC::auc(gbmboost.roc),3),
                "\nModel 2: GLM AUC=",round(pROC::auc(glm.allpredictors.roc),3), 
                "\nModel 3: Neural Net AUC=",round(pROC::auc(NN.roc),3))))

points(1-glm.allpredictors.roc$specificities, glm.allpredictors.roc$sensitivities, col="mediumpurple3", pch=16, cex=0.4)


points(1-gbmboost.roc$specificities, gbmboost.roc$sensitivities, col="springgreen4", pch=16, cex=0.4)


legend(0, 1, legend=c("Model 1", "Model 2", "Model 3"),
       col=c("springgreen4", "mediumpurple3", "steelblue3"), lty=1:1, cex=0.8)

lines(1-gbmboost.roc$specificities, gbmboost.roc$sensitivities, lwd=2, col="springgreen4")
lines(1-glm.allpredictors.roc$specificities, glm.allpredictors.roc$sensitivities, lwd=2, col="mediumpurple3")
lines(1-NN.roc$specificities, NN.roc$sensitivities, lwd=2, col="steelblue3")

```

# 1. Introduction 

## 1.1. Scope of the Problem
## 1.2. Project Goals

# 2. Methods

## 2.1. The Treatment Episode Data Set- Discharges (TEDS-D) Data
### Data Overview
### Data Cleaning
### Treatment Success Predictors
## 2.2. Study Sample Characteristics
## 2.3. Statistics
### Logistic Regression 
#### Least Absolute Shrinkage and Selection Operator
#### Elastic Net
### Random Forest
### Boosting Trees
### Neural Nets

# 3. Results

## 3.1 Models
### Logistic Regression 
#### Least Absolute Shrinkage and Selection Operator
#### Elastic Net
### Random Forest
### Boosting Trees
### Neural Nets

## 3.2. Model Comparisons

# 4. Conclusions and Implications

